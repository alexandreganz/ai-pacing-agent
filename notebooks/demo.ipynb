{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Pacing Agent - Interactive Demo\n",
    "\n",
    "This notebook demonstrates the **AI Pacing Agent** for automated media spend monitoring.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The AI Pacing Agent is an **autonomous LangGraph-based system** that:\n",
    "- Monitors media spend across Google and Meta platforms\n",
    "- Detects anomalies using variance thresholds\n",
    "- Makes intelligent decisions: log, alert, or autonomous halt\n",
    "- Uses confidence scoring as a safety guardrail\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Fetch & Reconcile ‚Üí Calculate Variance ‚Üí Assess Confidence\n",
    "                                             ‚Üì\n",
    "                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                         ‚Üì                                    ‚Üì\n",
    "                  [Low Confidence]                   [High Confidence]\n",
    "                  Escalate to Human                   Route by Severity\n",
    "                                                            ‚Üì\n",
    "                                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                                        ‚Üì                   ‚Üì               ‚Üì\n",
    "                                    Healthy             Warning         Critical\n",
    "                                   Log Only          Slack Alert    Autonomous Halt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.orchestrator import PacingOrchestrator\n",
    "from src.agents.pacing_brain import PacingBrain\n",
    "from src.api.mock_platform_api import MockPlatformAPI\n",
    "from src.api.internal_tracker import MockInternalTracker\n",
    "from src.models.spend import Platform\n",
    "from src.utils.audit_logger import AuditLogger\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Mock APIs\n",
    "\n",
    "First, let's create mock platform APIs that simulate realistic campaign data with various spend patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mock APIs with fixed seed for reproducibility\n",
    "google_api = MockPlatformAPI(Platform.GOOGLE, num_campaigns=10, seed=42)\n",
    "meta_api = MockPlatformAPI(Platform.META, num_campaigns=10, seed=43)\n",
    "internal_tracker = MockInternalTracker()\n",
    "\n",
    "print(\"‚úÖ Mock APIs initialized\")\n",
    "print(f\"\\nGoogle campaigns: {len(google_api.list_campaign_ids())}\")\n",
    "print(f\"Meta campaigns: {len(meta_api.list_campaign_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect Campaign Data\n",
    "\n",
    "Let's look at the mock campaign data to understand variance scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "google_stats = google_api.get_summary_stats()\n",
    "meta_stats = meta_api.get_summary_stats()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CAMPAIGN SUMMARY STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä GOOGLE Platform:\")\n",
    "print(f\"   Total campaigns:     {google_stats['total_campaigns']}\")\n",
    "print(f\"   Active:              {google_stats['active_campaigns']}\")\n",
    "print(f\"   Paused:              {google_stats['paused_campaigns']}\")\n",
    "print(f\"   Total target spend:  ${google_stats['total_target_spend']:,.2f}\")\n",
    "print(f\"   Total actual spend:  ${google_stats['total_actual_spend']:,.2f}\")\n",
    "print(f\"   Overall variance:    {google_stats['overall_variance_pct']:.1f}%\")\n",
    "print(f\"\\n   Scenario distribution:\")\n",
    "for scenario, count in google_stats['scenario_distribution'].items():\n",
    "    print(f\"     - {scenario}: {count} campaigns\")\n",
    "\n",
    "print(f\"\\nüìä META Platform:\")\n",
    "print(f\"   Total campaigns:     {meta_stats['total_campaigns']}\")\n",
    "print(f\"   Active:              {meta_stats['active_campaigns']}\")\n",
    "print(f\"   Paused:              {meta_stats['paused_campaigns']}\")\n",
    "print(f\"   Total target spend:  ${meta_stats['total_target_spend']:,.2f}\")\n",
    "print(f\"   Total actual spend:  ${meta_stats['total_actual_spend']:,.2f}\")\n",
    "print(f\"   Overall variance:    {meta_stats['overall_variance_pct']:.1f}%\")\n",
    "print(f\"\\n   Scenario distribution:\")\n",
    "for scenario, count in meta_stats['scenario_distribution'].items():\n",
    "    print(f\"     - {scenario}: {count} campaigns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Initialize Agent Components\n\nCreate the analyzer and confidence scorer with 70% confidence threshold."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize components (not full LangGraph brain due to known issue)\nfrom src.analyzers.pacing_analyzer import PacingAnalyzer\nfrom src.agents.confidence_scorer import ConfidenceScorer\n\naudit_logger = AuditLogger(log_file=\"demo_audit_log.jsonl\")\naudit_logger.clear_log()  # Clear previous runs\n\n# Create analyzer and confidence scorer\nanalyzer = PacingAnalyzer(\n    healthy_threshold=10.0,\n    warning_threshold=25.0\n)\nscorer = ConfidenceScorer()\n\nprint(\"‚úÖ Components initialized\")\nprint(f\"   Confidence threshold: 70%\")\nprint(f\"   Variance thresholds: <10% healthy, 10-25% warning, >25% critical\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Run Agent on Sample Campaigns\n\nLet's run the agent components on all Google campaigns and see the decisions.\n\n**Note**: This demo uses component-level processing (Analyzer + ConfidenceScorer) instead of the full LangGraph PacingBrain to ensure stability."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\" * 70)\nprint(\"RUNNING PACING AGENT ON GOOGLE CAMPAIGNS\")\nprint(\"=\" * 70 + \"\\n\")\n\nfrom src.models.spend import ReconciledSpend, PacingAlert\n\nalerts = []\nCONFIDENCE_THRESHOLD = 0.7\n\nfor campaign_id in google_api.list_campaign_ids():\n    print(f\"üìä Analyzing {campaign_id}...\", end=\" \")\n    \n    try:\n        # Fetch data from both sources\n        actual_record = google_api.get_campaign_spend(campaign_id)\n        target_record = internal_tracker.get_target_spend(campaign_id)\n        \n        # Calculate confidence scores\n        confidence_scores = scorer.calculate_confidence(\n            tracker_name=target_record.campaign_name,\n            api_name=actual_record.campaign_name,\n            tracker_metadata=target_record.metadata,\n            api_metadata=actual_record.metadata,\n            actual_timestamp=actual_record.timestamp\n        )\n        \n        # Create reconciled spend\n        reconciled = ReconciledSpend(\n            campaign_id=campaign_id,\n            campaign_name=actual_record.campaign_name,\n            platform=actual_record.platform,\n            target_spend=target_record.amount_usd,\n            actual_spend=actual_record.amount_usd,\n            target_timestamp=target_record.timestamp,\n            actual_timestamp=actual_record.timestamp,\n            metadata_match_score=confidence_scores[\"metadata_match_score\"],\n            name_similarity=confidence_scores[\"name_similarity\"],\n            data_freshness_score=confidence_scores[\"data_freshness_score\"]\n        )\n        \n        # Calculate variance\n        variance_result = analyzer.calculate_variance(reconciled)\n        \n        # Generate recommendation\n        recommendation = analyzer.generate_recommendation(variance_result, reconciled)\n        \n        # Determine action based on confidence and severity\n        if reconciled.confidence_score < CONFIDENCE_THRESHOLD:\n            action_taken = \"escalated_to_human\"\n            requires_human = True\n        elif variance_result[\"severity\"] == \"healthy\":\n            action_taken = \"logged_healthy\"\n            requires_human = False\n        elif variance_result[\"severity\"] == \"warning\":\n            action_taken = \"warning_alert_sent\"\n            requires_human = False\n        else:  # critical\n            action_taken = \"autonomous_halt_executed\"\n            requires_human = False\n        \n        # Create alert\n        alert = PacingAlert(\n            alert_id=f\"alert_{len(alerts)}\",\n            campaign_id=campaign_id,\n            severity=variance_result[\"severity\"],\n            variance_pct=variance_result[\"variance_pct\"],\n            confidence_score=reconciled.confidence_score,\n            action_taken=action_taken,\n            recommendation=recommendation,\n            requires_human=requires_human,\n            timestamp=datetime.utcnow(),\n            root_cause_analysis=f\"Variance of {variance_result['variance_pct']:.1f}% detected. \" +\n                               (\"Overspending\" if reconciled.is_overspending else \"Underspending\") +\n                               f\" by ${abs(actual_record.amount_usd - target_record.amount_usd):,.2f}\",\n            mitigation_plan=\"Review campaign targeting and adjust budget allocation accordingly.\"\n        )\n        \n        alerts.append(alert)\n        \n        # Log to audit trail\n        audit_logger.log_alert(alert)\n        \n        # Print result with emoji\n        emoji = {\"healthy\": \"‚úÖ\", \"warning\": \"‚ö†Ô∏è\", \"critical\": \"üö®\"}.get(alert.severity, \"‚ùì\")\n        print(f\"{emoji} {alert.severity.upper()} - {alert.action_taken} ({alert.variance_pct:.1f}% variance)\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error: {str(e)}\")\n\nprint(f\"\\n‚úÖ Processed {len(alerts)} campaigns\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Results\n",
    "\n",
    "Let's create a summary dataframe of all alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from alerts\n",
    "alert_data = [\n",
    "    {\n",
    "        \"Campaign ID\": alert.campaign_id,\n",
    "        \"Severity\": alert.severity,\n",
    "        \"Variance %\": f\"{alert.variance_pct:.1f}%\",\n",
    "        \"Confidence\": f\"{alert.confidence_score:.1%}\",\n",
    "        \"Action Taken\": alert.action_taken,\n",
    "        \"Requires Human\": \"Yes\" if alert.requires_human else \"No\"\n",
    "    }\n",
    "    for alert in alerts\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(alert_data)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PACING RESULTS SUMMARY\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count by severity\n",
    "severity_counts = df['Severity'].value_counts()\n",
    "action_counts = df['Action Taken'].value_counts()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìä By Severity:\")\n",
    "for severity, count in severity_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    emoji = {\"healthy\": \"‚úÖ\", \"warning\": \"‚ö†Ô∏è\", \"critical\": \"üö®\"}.get(severity, \"‚ùì\")\n",
    "    print(f\"   {emoji} {severity.capitalize():<10} {count:>2} campaigns ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\nü§ñ By Action:\")\n",
    "for action, count in action_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   - {action:<25} {count:>2} ({pct:.1f}%)\")\n",
    "\n",
    "# Autonomous vs Human\n",
    "autonomous = sum(1 for alert in alerts if alert.is_autonomous_action)\n",
    "escalated = sum(1 for alert in alerts if alert.requires_human)\n",
    "\n",
    "print(f\"\\nüéØ Decision Breakdown:\")\n",
    "print(f\"   Autonomous actions:  {autonomous} ({autonomous/len(alerts)*100:.1f}%)\")\n",
    "print(f\"   Human escalations:   {escalated} ({escalated/len(alerts)*100:.1f}%)\")\n",
    "print(f\"   Alerts sent:         {len([a for a in alerts if a.severity in ['warning', 'critical']])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detailed Analysis of Critical Campaigns\n",
    "\n",
    "Let's examine critical campaigns in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_alerts = [a for a in alerts if a.severity == \"critical\"]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"CRITICAL CAMPAIGN DETAILS ({len(critical_alerts)} campaigns)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, alert in enumerate(critical_alerts, 1):\n",
    "    print(f\"\\nüö® Campaign {i}: {alert.campaign_id}\")\n",
    "    print(f\"   Variance:      {alert.variance_pct:.1f}%\")\n",
    "    print(f\"   Confidence:    {alert.confidence_score:.1%}\")\n",
    "    print(f\"   Action:        {alert.action_taken}\")\n",
    "    print(f\"\\n   Recommendation:\")\n",
    "    print(f\"   {alert.recommendation[:200]}...\")\n",
    "    \n",
    "    if alert.root_cause_analysis:\n",
    "        print(f\"\\n   Root Cause Analysis:\")\n",
    "        for line in alert.root_cause_analysis.split('\\n')[:3]:\n",
    "            print(f\"   {line}\")\n",
    "    \n",
    "    if alert.mitigation_plan:\n",
    "        print(f\"\\n   Mitigation Plan (first 3):\")\n",
    "        for line in alert.mitigation_plan.split('\\n')[:3]:\n",
    "            print(f\"   {line}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Audit Trail Analysis\n",
    "\n",
    "Let's examine the audit log to see all decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audit log summary\n",
    "audit_stats = audit_logger.get_summary_stats()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"AUDIT LOG SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTotal events logged:    {audit_stats['total_events']}\")\n",
    "print(f\"Log file:              {audit_stats['log_file']}\")\n",
    "print(f\"Log size:              {audit_stats['log_size_bytes']:,} bytes\")\n",
    "\n",
    "print(\"\\nüìù Event Types:\")\n",
    "for event_type, count in audit_stats['event_types'].items():\n",
    "    print(f\"   - {event_type:<25} {count:>3}\")\n",
    "\n",
    "print(\"\\nüö® Alerts by Severity:\")\n",
    "for severity, count in audit_stats['alerts_by_severity'].items():\n",
    "    print(f\"   - {severity:<10} {count:>3}\")\n",
    "\n",
    "print(\"\\nüéØ Decisions by Type:\")\n",
    "for decision, count in audit_stats['decisions_by_type'].items():\n",
    "    print(f\"   - {decision:<20} {count:>3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sample Audit Log Entries\n",
    "\n",
    "Let's look at actual log entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recent events\n",
    "recent_events = audit_logger.get_events(limit=5)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECENT AUDIT LOG ENTRIES (5 most recent)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for event in recent_events:\n",
    "    print(f\"\\n{json.dumps(event, indent=2)}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Full Orchestrator Demo\n",
    "\n",
    "Now let's run the full orchestrator that monitors both Google and Meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear previous logs\n",
    "audit_logger.clear_log()\n",
    "\n",
    "# Initialize orchestrator\n",
    "orchestrator = PacingOrchestrator(\n",
    "    platforms=[Platform.GOOGLE, Platform.META],\n",
    "    slack_webhook=None,\n",
    "    audit_log_file=\"demo_audit_log.jsonl\",\n",
    "    confidence_threshold=0.7\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Orchestrator initialized\")\n",
    "print(\"   Monitoring: Google + Meta\")\n",
    "print(\"   Total campaigns: 20\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run monitoring for all campaigns\n",
    "results = orchestrator.run_all_campaigns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cross-Platform Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CROSS-PLATFORM ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for platform, alerts in results.items():\n",
    "    healthy = sum(1 for a in alerts if a.severity == \"healthy\")\n",
    "    warning = sum(1 for a in alerts if a.severity == \"warning\")\n",
    "    critical = sum(1 for a in alerts if a.severity == \"critical\")\n",
    "    autonomous = sum(1 for a in alerts if a.is_autonomous_action)\n",
    "    \n",
    "    print(f\"\\nüìä {platform.value.upper()} Platform:\")\n",
    "    print(f\"   Total campaigns:     {len(alerts)}\")\n",
    "    print(f\"   ‚úÖ Healthy:          {healthy} ({healthy/len(alerts)*100:.1f}%)\")\n",
    "    print(f\"   ‚ö†Ô∏è  Warning:          {warning} ({warning/len(alerts)*100:.1f}%)\")\n",
    "    print(f\"   üö® Critical:         {critical} ({critical/len(alerts)*100:.1f}%)\")\n",
    "    print(f\"   ü§ñ Autonomous acts:  {autonomous}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Key Takeaways\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "1. **Autonomous Decision-Making**: Agent correctly classified 20 campaigns into healthy/warning/critical\n",
    "2. **Safety Guardrails**: Low confidence scenarios escalated to humans\n",
    "3. **Root Cause Analysis**: Automatic diagnosis of why anomalies occurred\n",
    "4. **Mitigation Planning**: Actionable recommendations for prevention\n",
    "5. **Complete Audit Trail**: Every decision logged for compliance\n",
    "\n",
    "### Decision Matrix\n",
    "\n",
    "| Variance | Confidence | Action |\n",
    "|----------|-----------|--------|\n",
    "| < 10% | Any | Log only |\n",
    "| 10-25% | ‚â• 70% | Slack alert |\n",
    "| 10-25% | < 70% | Escalate to human |\n",
    "| > 25% | ‚â• 70% | Autonomous halt + alert |\n",
    "| > 25% | < 70% | Escalate to human |\n",
    "| Zero delivery | Any | Autonomous halt + alert |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To move to production:\n",
    "1. Replace `MockPlatformAPI` with real Google Ads and Meta Marketing APIs\n",
    "2. Configure Slack webhook for real-time alerts\n",
    "3. Set up scheduled runs (every 4 hours via cron/Airflow)\n",
    "4. Deploy to cloud infrastructure (Docker + GCP/AWS)\n",
    "5. Add monitoring dashboards (Prometheus + Grafana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚úÖ Demo completed successfully!\")\n",
    "print(f\"\\nüìù Audit log saved to: {audit_logger.log_path}\")\n",
    "print(\"\\nTo run tests: pytest tests/ -v\")\n",
    "print(\"To run from CLI: python example.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}